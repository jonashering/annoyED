/*
 * This Java source file was generated by the Gradle 'init' task.
 */
package annoyED;

import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.serialization.StringSerializer;
import org.apache.kafka.common.serialization.Deserializer;
import org.apache.kafka.common.serialization.Serde;
import org.apache.kafka.streams.Topology;
import org.apache.kafka.streams.TopologyTestDriver;
import org.apache.kafka.streams.test.ConsumerRecordFactory;
import org.junit.After;
import org.junit.Before;
import org.junit.Test;

import annoyED.serdes.SerdesFactory;
import annoyED.store.Datapoint;
import annoyED.store.NearestNeighborCandidates;

import java.util.Vector;



public class AppTest {

    private TopologyTestDriver testDriver;
    private Serde<Datapoint> dataSerdes = SerdesFactory.from(Datapoint.class);
    private Serde<NearestNeighborCandidates> sinkValueSerde = SerdesFactory.from(NearestNeighborCandidates.class);
    private Deserializer<NearestNeighborCandidates> hashsetDeserializer = sinkValueSerde.deserializer();
    private Deserializer<Datapoint> datapointDeserializer = dataSerdes.deserializer();
    private ConsumerRecordFactory<String, Datapoint> recordFactory = new ConsumerRecordFactory<String, Datapoint>(new StringSerializer(), dataSerdes.serializer());

    @Before
    public void setup() {
        App app = new App();
        Topology topology = app.build();

        testDriver = new TopologyTestDriver(topology, App.getStreamsConfig());
    }

    @After
    public void tearDown() {
        try {
            testDriver.close();
        } catch (final RuntimeException e) {
            System.out.println("Ignoring exception, test failing in Windows due this exception:" + e.getLocalizedMessage());
        }
    }

    @Test
    public void testOneWord() {
        Vector<Double> a = new Vector<Double>();
        a.add(1d);
        a.add(1d);
        Datapoint data_a = new Datapoint("Test-5", a, true, true);
        Vector<Double> b = new Vector<Double>();
        b.add(5d);
        b.add(5d);
        Datapoint data_b = new Datapoint("Test-7", b, true, true);
        Vector<Double> c = new Vector<Double>();
        c.add(2d);
        c.add(2d);
        Datapoint data_c = new Datapoint("Test-6", c, true, true);
        Vector<Double> d = new Vector<Double>();
        d.add(7d);
        d.add(7d);
        Datapoint data_d= new Datapoint("Test-8", d, true, true);
        testDriver.pipeInput(recordFactory.create("source-topic", "Test-5", data_a));
        testDriver.pipeInput(recordFactory.create("source-topic", "Test-6", data_c));
        testDriver.pipeInput(recordFactory.create("source-topic", "Test-7", data_b));
        testDriver.pipeInput(recordFactory.create("source-topic", "Test-8", data_d));
        testDriver.pipeInput(recordFactory.create("source-topic", "Test-9", data_b));
        testDriver.pipeInput(recordFactory.create("source-topic", "Test-10", data_c));
        testDriver.pipeInput(recordFactory.create("source-topic", "Test-11", data_a));

        ProducerRecord<Datapoint, NearestNeighborCandidates> outputRecord = testDriver.readOutput("sink-topic", datapointDeserializer, hashsetDeserializer);

        // OutputVerifier.compareKeyValue(outputRecord, "Test-5", data_a);
        System.err.println(outputRecord.key().datapointID);
        for (Datapoint dp : outputRecord.value().candidates) {
            System.err.println(dp.datapointID);
        }
        outputRecord = testDriver.readOutput("sink-topic", datapointDeserializer, hashsetDeserializer);
        // OutputVerifier.compareKeyValue(outputRecord, "Test-6", data_c);
        //assertNull(testDriver.readOutput("sink-topic", datapointDeserializer, hashsetDeserializer));
    }

}
